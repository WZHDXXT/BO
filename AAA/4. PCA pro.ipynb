{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ioh import get_problem, ProblemClass\n",
    "from ioh import logger\n",
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "import BA \n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.decomposition import KernelPCA\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "from sklearn.random_projection import GaussianRandomProjection\n",
    "import botorch\n",
    "import gpytorch\n",
    "from gpytorch.constraints import Interval\n",
    "from gpytorch.kernels import MaternKernel, ScaleKernel, RBFKernel\n",
    "from gpytorch.likelihoods import GaussianLikelihood\n",
    "from gpytorch.mlls import ExactMarginalLogLikelihood\n",
    "from torch.quasirandom import SobolEngine\n",
    "\n",
    "from botorch.acquisition.analytic import LogExpectedImprovement\n",
    "from botorch.exceptions import ModelFittingError\n",
    "from botorch.fit import fit_gpytorch_mll\n",
    "from botorch.generation import MaxPosteriorSampling\n",
    "from botorch.models import SingleTaskGP\n",
    "from botorch.optim import optimize_acqf\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Running on {device}\")\n",
    "dtype = torch.float\n",
    "SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")\n",
    "\n",
    "# problem dimension\n",
    "dim = 40 if not SMOKE_TEST else 50\n",
    "projected_dim = 15\n",
    "\n",
    "# initial sample points\n",
    "n_init = 10 if not SMOKE_TEST else 4\n",
    "max_cholesky_size = float(\"inf\")\n",
    "\n",
    "problem = get_problem(1, dimension=dim, instance=2, problem_class=ProblemClass.BBOB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "EVALUATION_BUDGET = 100 if not SMOKE_TEST else 10\n",
    "NUM_RESTARTS = 3 if not SMOKE_TEST else 2\n",
    "RAW_SAMPLES = 51 if not SMOKE_TEST else 4\n",
    "N_CANDIDATES = min(dim, max(200, 20 * dim)) if not SMOKE_TEST else 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S before increase\n",
      "tensor([[ 0.4321,  0.0342,  0.1614,  0.4346, -0.3942, -0.5921,  0.0643,  0.1235,\n",
      "         -0.1440,  0.2261],\n",
      "        [-0.0670,  0.4098, -0.5844, -0.2170, -0.2966,  0.0608,  0.2185, -0.2141,\n",
      "         -0.2721,  0.4238],\n",
      "        [ 0.0267, -0.5508, -0.3849, -0.1510, -0.1583, -0.1534, -0.4961, -0.0355,\n",
      "          0.3634,  0.3113]], dtype=torch.float64)\n",
      "X before increase\n",
      "tensor([[87, 83],\n",
      "        [68, 34],\n",
      "        [15, 47],\n",
      "        [63, 22],\n",
      "        [51, 41],\n",
      "        [75, 20],\n",
      "        [72, 27]])\n"
     ]
    }
   ],
   "source": [
    "n_sample = 40\n",
    "X_sample = BA.get_initial_points(10, n_sample)\n",
    "S = BA.embedding_matrix_pca(input_dim=10, target_dim=3, data=X_sample)\n",
    "X = torch.randint(100, (7, 2))\n",
    "print(f\"S before increase\\n{S}\")\n",
    "print(f\"X before increase\\n{X}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "InputDataError",
     "evalue": "Expected all inputs to share the same dtype. Got torch.float64 for X, torch.float32 for Y, and None for Yvar.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInputDataError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 22\u001b[0m\n\u001b[1;32m     20\u001b[0m train_Y \u001b[38;5;241m=\u001b[39m (Y_baxus \u001b[38;5;241m-\u001b[39m Y_baxus\u001b[38;5;241m.\u001b[39mmean()) \u001b[38;5;241m/\u001b[39m Y_baxus\u001b[38;5;241m.\u001b[39mstd()\n\u001b[1;32m     21\u001b[0m likelihood \u001b[38;5;241m=\u001b[39m GaussianLikelihood(noise_constraint\u001b[38;5;241m=\u001b[39mInterval(\u001b[38;5;241m1e-8\u001b[39m, \u001b[38;5;241m1e-3\u001b[39m))\n\u001b[0;32m---> 22\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mSingleTaskGP\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m        \u001b[49m\u001b[43mX_baxus_target\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlikelihood\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlikelihood\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m mll \u001b[38;5;241m=\u001b[39m ExactMarginalLogLikelihood(model\u001b[38;5;241m.\u001b[39mlikelihood, model)\n\u001b[1;32m     27\u001b[0m     \u001b[38;5;66;03m# Fit the model using Cholesky context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/BO/lib/python3.10/site-packages/botorch/models/gp_regression.py:164\u001b[0m, in \u001b[0;36mSingleTaskGP.__init__\u001b[0;34m(self, train_X, train_Y, train_Yvar, likelihood, covar_module, mean_module, outcome_transform, input_transform)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    132\u001b[0m     train_X: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    139\u001b[0m     input_transform: Optional[InputTransform] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    140\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    141\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;124;03m        train_X: A `batch_shape x n x d` tensor of training features.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;124;03m            forward pass.\u001b[39;00m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_tensor_args\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_X\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Y\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mYvar\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_Yvar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    165\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m outcome_transform \u001b[38;5;241m==\u001b[39m DEFAULT:\n\u001b[1;32m    166\u001b[0m         outcome_transform \u001b[38;5;241m=\u001b[39m Standardize(\n\u001b[1;32m    167\u001b[0m             m\u001b[38;5;241m=\u001b[39mtrain_Y\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m], batch_shape\u001b[38;5;241m=\u001b[39mtrain_X\u001b[38;5;241m.\u001b[39mshape[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    168\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/BO/lib/python3.10/site-packages/botorch/models/gpytorch.py:123\u001b[0m, in \u001b[0;36mGPyTorchModel._validate_tensor_args\u001b[0;34m(X, Y, Yvar, strict)\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;66;03m# Check the dtypes.\u001b[39;00m\n\u001b[1;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;129;01mor\u001b[39;00m (Yvar \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m Y\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m Yvar\u001b[38;5;241m.\u001b[39mdtype):\n\u001b[0;32m--> 123\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m InputDataError(\n\u001b[1;32m    124\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected all inputs to share the same dtype. Got \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    125\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for X, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for Y, and \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    126\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mYvar\u001b[38;5;241m.\u001b[39mdtype\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mif\u001b[39;00m\u001b[38;5;250m \u001b[39mYvar\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mis\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01melse\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for Yvar.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m X\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfloat64:\n\u001b[1;32m    129\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    130\u001b[0m         _get_single_precision_warning(\u001b[38;5;28mstr\u001b[39m(X\u001b[38;5;241m.\u001b[39mdtype)),\n\u001b[1;32m    131\u001b[0m         InputDataWarning,\n\u001b[1;32m    132\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m,  \u001b[38;5;66;03m# Warn at model constructor call.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     )\n",
      "\u001b[0;31mInputDataError\u001b[0m: Expected all inputs to share the same dtype. Got torch.float64 for X, torch.float32 for Y, and None for Yvar."
     ]
    }
   ],
   "source": [
    "state = BA.BaxusState(dim=dim, eval_budget=EVALUATION_BUDGET\n",
    ")\n",
    "n_sample = n_init\n",
    "X_sample = BA.get_initial_points(state.dim, n_sample)\n",
    "S = BA.embedding_matrix_pca(input_dim=state.dim, target_dim=state.d_init, data=X_sample)\n",
    "\n",
    "    # X_baxus_target = BA.get_initial_points(state.d_init, n_init)\n",
    "X_baxus_target = X_sample @ S.T\n",
    "X_baxus_target = torch.clamp(X_baxus_target, min=-5, max=5)\n",
    "\n",
    "    # X_baxus_input = X_baxus_target @ S\n",
    "X_baxus_input = X_baxus_target@ S\n",
    "\n",
    "Y_baxus = torch.tensor(\n",
    "            [-problem(list(x)) for x in X_baxus_input], dtype=dtype, device=device\n",
    "        ).unsqueeze(-1)\n",
    "with botorch.settings.validate_input_scaling(False):\n",
    "    for _ in range(EVALUATION_BUDGET - n_sample):  # Run until evaluation budget depleted\n",
    "                # Fit a GP model\n",
    "            train_Y = (Y_baxus - Y_baxus.mean()) / Y_baxus.std()\n",
    "            likelihood = GaussianLikelihood(noise_constraint=Interval(1e-8, 1e-3))\n",
    "            model = SingleTaskGP(\n",
    "                    X_baxus_target, train_Y, likelihood=likelihood\n",
    "                )\n",
    "            mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "\n",
    "                # Fit the model using Cholesky context\n",
    "            with gpytorch.settings.max_cholesky_size(max_cholesky_size):\n",
    "                try:\n",
    "                    fit_gpytorch_mll(mll)\n",
    "                except ModelFittingError:\n",
    "                        # Use Adam-based optimization if Cholesky decomposition fails\n",
    "                    optimizer = torch.optim.Adam([{\"params\": model.parameters()}], lr=0.1)\n",
    "                    for _ in range(200):\n",
    "                        optimizer.zero_grad()\n",
    "                        output = model(X_baxus_target)\n",
    "                        loss = -mll(output, train_Y.flatten())\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                    # Generate new candidates\n",
    "                X_next_target = BA.create_candidate(\n",
    "                        state=state,\n",
    "                        model=model,\n",
    "                        X=X_baxus_target,\n",
    "                        Y=train_Y,\n",
    "                        device=device,\n",
    "                        dtype=dtype,\n",
    "                        n_candidates=N_CANDIDATES,\n",
    "                        num_restarts=NUM_RESTARTS,\n",
    "                        raw_samples=RAW_SAMPLES,\n",
    "                        acqf=\"ts\",\n",
    "                    )\n",
    "                \n",
    "                # Map new candidates to high-dimensional space\n",
    "            X_next_input = X_next_target @ S\n",
    "            Y_next = torch.tensor(\n",
    "                    [-problem(list(x)) for x in X_next_input], dtype=dtype, device=device\n",
    "                ).unsqueeze(-1)\n",
    "\n",
    "                # Update state and concatenate new points\n",
    "            state = BA.update_state(state=state, Y_next=Y_next)\n",
    "            X_baxus_input = torch.cat((X_baxus_input, X_next_input), dim=0)\n",
    "            X_baxus_target = torch.cat((X_baxus_target, X_next_target), dim=0)\n",
    "            Y_baxus = torch.cat((Y_baxus, Y_next), dim=0)\n",
    "                \n",
    "            print(\n",
    "                    f\"iteration {len(X_baxus_input)}, d={len(X_baxus_target.T)})  Best value: {state.best_value:.3}, TR length: {state.length:.3}\"\n",
    "                )\n",
    "\n",
    "            if state.restart_triggered:\n",
    "                state.restart_triggered = False\n",
    "                print(\"increasing target space\")\n",
    "\n",
    "                S, X_baxus_target = BA.increase_embedding_and_observations(\n",
    "                        S, X_baxus_target, state.new_bins_on_split\n",
    "                    )\n",
    "                print(f\"new dimensionality: {len(S)}\")\n",
    "                    \n",
    "                state.target_dim = len(S)\n",
    "                state.length = state.length_init\n",
    "                state.failure_counter = 0\n",
    "                state.success_counter = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BO",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
